{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb98c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.6.2)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: clang~=5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: cached-property in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (58.5.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09cc0110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              1       89             66             23       94  28.1   \n",
       "1              0      137             40             35      168  43.1   \n",
       "2              3       78             50             32       88  31.0   \n",
       "3              2      197             70             45      543  30.5   \n",
       "4              1      189             60             23      846  30.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "387            0      181             88             44      510  43.3   \n",
       "388            1      128             88             39      110  36.5   \n",
       "389            2       88             58             26       16  28.4   \n",
       "390           10      101             76             48      180  32.9   \n",
       "391            5      121             72             23      112  26.2   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.167   21        0  \n",
       "1                       2.288   33        1  \n",
       "2                       0.248   26        1  \n",
       "3                       0.158   53        1  \n",
       "4                       0.398   59        1  \n",
       "..                        ...  ...      ...  \n",
       "387                     0.222   26        1  \n",
       "388                     1.057   37        1  \n",
       "389                     0.766   22        0  \n",
       "390                     0.171   63        0  \n",
       "391                     0.245   30        0  \n",
       "\n",
       "[392 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 6.a\n",
    "import boto3, botocore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from itertools import product\n",
    "\n",
    "## fetch file content from s3\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('danhtran358-data-445-bucket')\n",
    "\n",
    "bucket_object = bucket.Object('project_cleaned_data.csv')\n",
    "## read file content to data-frame\n",
    "diabetes_cleaned = pd.read_csv(bucket_object.get().get('Body'))\n",
    "diabetes_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a853a49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>35</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>35</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>48</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>27</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>23</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>31</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  SkinThickness   BMI  DiabetesPedigreeFunction  Age  \\\n",
       "0              6      148             35  33.6                     0.627   50   \n",
       "1              1       85             29  26.6                     0.351   31   \n",
       "2              1       89             23  28.1                     0.167   21   \n",
       "3              0      137             35  43.1                     2.288   33   \n",
       "4              3       78             32  31.0                     0.248   26   \n",
       "..           ...      ...            ...   ...                       ...  ...   \n",
       "529            9      170             31  44.0                     0.403   43   \n",
       "530           10      101             48  32.9                     0.171   63   \n",
       "531            2      122             27  36.8                     0.340   27   \n",
       "532            5      121             23  26.2                     0.245   30   \n",
       "533            1       93             31  30.4                     0.315   23   \n",
       "\n",
       "     Outcome  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  \n",
       "..       ...  \n",
       "529        1  \n",
       "530        0  \n",
       "531        0  \n",
       "532        0  \n",
       "533        0  \n",
       "\n",
       "[534 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_object = bucket.Object('project_cleaned_data_extended_after_LASSO.csv')\n",
    "## read file content to data-frame\n",
    "diabetes_extended = pd.read_csv(bucket_object.get().get('Body'))\n",
    "diabetes_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6931c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use dataframes to store parameters to build models and store total scores\n",
    "def expand_grid(dictionary):\n",
    "    return pd.DataFrame([row for row in product(*dictionary.values())], columns = dictionary.keys())\n",
    "\n",
    "dictionary = {'extended_data' : ['Y', 'N'], 'input_layer': [6, 8], 'mid_layer_1': [2, 3, 4], 'mid_layer_2': [2, 3, 4], 'total_loops' : [0],\n",
    "                 'mlp' : ['mlp1_tanh', 'mlp1_relu', 'mlp2_tanh', 'mlp2_relu', 'mlp2_tanh_relu', 'mlp2_relu_tanh']}\n",
    "\n",
    "## lists of cut-off values and types of score to evaluate models\n",
    "cut_off = [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "score_to_evaluate = ['precision', 'recall', 'f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe5f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to write write data_frame to csv file object in S3 bucket\n",
    "def write_data_to_s3(file_name, data_frame):\n",
    "    ## file object in s3 bucket\n",
    "    data_file = bucket.Object(file_name)\n",
    "    \n",
    "    ## add content from the lists of recall scores\n",
    "    content = data_frame.to_csv(index=False)\n",
    "\n",
    "    ## store as new csv file\n",
    "    data_file.put(Body = content)\n",
    "    \n",
    "\n",
    "## function to read Random Forest data stored in s3 csv to dataframe\n",
    "def read_data_from_s3(file_name):\n",
    "    try:\n",
    "        ## file object in s3 bucket\n",
    "        data_file = bucket.Object(file_name)\n",
    "        \n",
    "        data_file.load()\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            ## file does not exist yet, create new file\n",
    "            results = expand_grid(dictionary)\n",
    "            \n",
    "            ## will not work on extended data with 8 feature columns\n",
    "            results = results.drop(results[(results['extended_data'] == 'Y') & (results['input_layer'] == 8)].index)\n",
    "            \n",
    "            ## create columns for all types of cut-off values and scores\n",
    "            for i in range(len(cut_off)):\n",
    "                for j in range(len(score_to_evaluate)):\n",
    "                    col = str(cut_off[i]) + '_' + score_to_evaluate[j]\n",
    "                    results[col] = 0.0\n",
    "                    \n",
    "            ## write brand new and empty file to s3\n",
    "            write_data_to_s3(file_name, results)\n",
    "            \n",
    "            ## return the dataframe from newly created file\n",
    "            return pd.read_csv(data_file.get().get('Body'))\n",
    "    else:\n",
    "        ## return the dataframe already stored\n",
    "        return pd.read_csv(data_file.get().get('Body'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f51e07ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp1_tanh_predict(X_train, X_test, Y_train, input_layer, mid_layer_1):\n",
    "    ## Multilayer perceptron 1 mid layer tanh\n",
    "    ## Define mlp structure\n",
    "    mlp_md1 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    mlp_md1.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = 500, verbose = 0)\n",
    "\n",
    "    ## Predict probability \n",
    "    predict_md1 = mlp_md1.predict(X_test)[:,1]\n",
    "    \n",
    "    return predict_md1\n",
    "    \n",
    "\n",
    "def mlp1_relu_predict(X_train, X_test, Y_train, input_layer, mid_layer_1):\n",
    "    ## Multilayer perceptron 1 mid layer relu\n",
    "    ## Define mlp structure\n",
    "    mlp_md2 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md2.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    mlp_md2.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = 500, verbose = 0)\n",
    "\n",
    "    ## Predict probability\n",
    "    predict_md2 = mlp_md2.predict(X_test)[:,1]\n",
    "\n",
    "    return predict_md2\n",
    "\n",
    "\n",
    "def mlp2_tanh_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, mid_layer_2):\n",
    "    ## Multilayer perceptron 2 mid layer, both tanh\n",
    "    ## Define mlp structure\n",
    "    mlp_md1 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(mid_layer_2, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    mlp_md1.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = 500, verbose = 0)\n",
    "\n",
    "    ## Predict probability \n",
    "    predict_md1 = mlp_md1.predict(X_test)[:,1]\n",
    "    \n",
    "    return predict_md1\n",
    "    \n",
    "\n",
    "def mlp2_relu_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, mid_layer_2):\n",
    "    ## Multilayer perceptron 2 layers, both relu\n",
    "    ## Define mlp structure\n",
    "    mlp_md2 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(mid_layer_2, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md2.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    mlp_md2.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = 500, verbose = 0)\n",
    "\n",
    "    ## Predict probability\n",
    "    predict_md2 = mlp_md2.predict(X_test)[:,1]\n",
    "\n",
    "    return predict_md2\n",
    "\n",
    "\n",
    "def mlp2_tanh_relu_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, mid_layer_2):\n",
    "    ## Multilayer perceptron 2 layers, tanh and relu\n",
    "    ## Define mlp structure\n",
    "    mlp_md1 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(mid_layer_2, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    mlp_md1.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = 500, verbose = 0)\n",
    "\n",
    "    ## Predict probability \n",
    "    predict_md1 = mlp_md1.predict(X_test)[:,1]\n",
    "    \n",
    "    return predict_md1\n",
    "    \n",
    "\n",
    "def mlp2_relu_tanh_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, mid_layer_2):\n",
    "    ## Multilayer perceptron 2 layers, relu and tanh\n",
    "    ## Define mlp structure\n",
    "    mlp_md2 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(mid_layer_2, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md2.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    mlp_md2.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = 500, verbose = 0)\n",
    "\n",
    "    ## Predict probability\n",
    "    predict_md2 = mlp_md2.predict(X_test)[:,1]\n",
    "\n",
    "    return predict_md2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6c721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef9c6e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build the appropriate model and update the result dataset after each model is built\n",
    "def update_results(X_train, X_test, Y_train, Y_test, results, combo_number):\n",
    "    parameters = results.loc[combo_number]\n",
    "    \n",
    "    if parameters['mlp'] == 'mlp1_tanh':\n",
    "        pred = mlp1_tanh_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp1_relu':\n",
    "        pred = mlp1_relu_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp2_tanh':\n",
    "        pred = mlp2_tanh_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['mid_layer_2'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp2_relu':\n",
    "        pred = mlp2_relu_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['mid_layer_2'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp2_tanh_relu':\n",
    "        pred = mlp2_tanh_relu_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['mid_layer_2'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp2_relu_tanh':\n",
    "        pred = mlp2_relu_tanh_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['mid_layer_2'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "\n",
    "## update the scores in result dataset after each model is built\n",
    "def update_result_scores(pred, Y_test, results, combo_number):\n",
    "    for cut_off_id in range(len(cut_off)):\n",
    "        \n",
    "        ## classify labels\n",
    "        current_cut_off = cut_off[cut_off_id]\n",
    "        pred_labels = np.where(pred < current_cut_off, 0, 1)\n",
    "        \n",
    "        for score_id in range(len(score_to_evaluate)):\n",
    "            \n",
    "            ## updated the appropriate score\n",
    "            current_score = score_to_evaluate[score_id]\n",
    "            score_column = str(current_cut_off) + '_' + current_score\n",
    "            \n",
    "            if current_score == 'precision':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + precision_score(Y_test, pred_labels, zero_division = 0)\n",
    "            \n",
    "            elif current_score == 'recall':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + recall_score(Y_test, pred_labels)\n",
    "                \n",
    "            elif current_score == 'f1': \n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + f1_score(Y_test, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41405afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining input and target variables\n",
    "X = diabetes_cleaned.drop(columns = ['Outcome'])\n",
    "Y = diabetes_cleaned['Outcome']\n",
    "X_lasso = X.drop(columns = ['BloodPressure', 'Insulin'])\n",
    "X_extended = diabetes_extended.drop(columns = ['Outcome'])\n",
    "Y_extended = diabetes_extended['Outcome']\n",
    "\n",
    "## read MLP data stored in s3 file\n",
    "data_file_name = 'project_mlp_result.csv'\n",
    "results = read_data_from_s3(data_file_name)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "## total_loops column keeps the number of loops already done, we only loop the rest until 100 times done\n",
    "for loop_number in range(results.at[1, 'total_loops'], 100):\n",
    "    \n",
    "    ## Build MLP models for each parameter combination and store scores\n",
    "    for combo_number in range(results.shape[0]):\n",
    "        parameters = results.loc[combo_number]\n",
    "        \n",
    "        if parameters['extended_data'] == 'N':\n",
    "            \n",
    "            if parameters['input_layer'] == 6:\n",
    "                ## cleaned data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_lasso, Y, test_size = 0.2, stratify = Y)\n",
    "                \n",
    "            else:\n",
    "                ## cleaned data with all features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "                \n",
    "        else:\n",
    "        \n",
    "            if parameters['input_layer'] == 6:\n",
    "                ## extended data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_extended, Y_extended, test_size = 0.2, stratify = Y_extended)\n",
    "                \n",
    "        ## scale input variables to 0-1 scale\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.fit_transform(X_test)\n",
    "        \n",
    "        update_results(X_train, X_test, Y_train, Y_test, results, combo_number)\n",
    "        \n",
    "    results['total_loops'] = loop_number + 1\n",
    "    ## Writing data to s3\n",
    "    write_data_to_s3(data_file_name, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0a5fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.drop(results[(results['extended_data'] == 'Y') & (results['input_layer'] == 8)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfc35f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0.2_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.25_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.3_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.35_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.4_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.45_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.5_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>0.503686</td>\n",
       "      <td>16</td>\n",
       "      <td>0.502438</td>\n",
       "      <td>39</td>\n",
       "      <td>0.497604</td>\n",
       "      <td>39</td>\n",
       "      <td>0.484405</td>\n",
       "      <td>3</td>\n",
       "      <td>0.442011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307056</td>\n",
       "      <td>102</td>\n",
       "      <td>0.186533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.503683</td>\n",
       "      <td>4</td>\n",
       "      <td>0.502213</td>\n",
       "      <td>3</td>\n",
       "      <td>0.493571</td>\n",
       "      <td>57</td>\n",
       "      <td>0.483656</td>\n",
       "      <td>39</td>\n",
       "      <td>0.434485</td>\n",
       "      <td>24</td>\n",
       "      <td>0.297437</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.503532</td>\n",
       "      <td>39</td>\n",
       "      <td>0.501544</td>\n",
       "      <td>21</td>\n",
       "      <td>0.493405</td>\n",
       "      <td>3</td>\n",
       "      <td>0.480046</td>\n",
       "      <td>31</td>\n",
       "      <td>0.433801</td>\n",
       "      <td>102</td>\n",
       "      <td>0.290820</td>\n",
       "      <td>24</td>\n",
       "      <td>0.180145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>0.503526</td>\n",
       "      <td>20</td>\n",
       "      <td>0.501452</td>\n",
       "      <td>22</td>\n",
       "      <td>0.492306</td>\n",
       "      <td>58</td>\n",
       "      <td>0.476445</td>\n",
       "      <td>57</td>\n",
       "      <td>0.433126</td>\n",
       "      <td>84</td>\n",
       "      <td>0.290424</td>\n",
       "      <td>18</td>\n",
       "      <td>0.176986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>0.503494</td>\n",
       "      <td>53</td>\n",
       "      <td>0.501002</td>\n",
       "      <td>45</td>\n",
       "      <td>0.492275</td>\n",
       "      <td>111</td>\n",
       "      <td>0.476319</td>\n",
       "      <td>111</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>103</td>\n",
       "      <td>0.290160</td>\n",
       "      <td>156</td>\n",
       "      <td>0.173702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>120</td>\n",
       "      <td>0.489312</td>\n",
       "      <td>73</td>\n",
       "      <td>0.475981</td>\n",
       "      <td>72</td>\n",
       "      <td>0.451142</td>\n",
       "      <td>158</td>\n",
       "      <td>0.404111</td>\n",
       "      <td>107</td>\n",
       "      <td>0.290950</td>\n",
       "      <td>17</td>\n",
       "      <td>0.108869</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>78</td>\n",
       "      <td>0.489058</td>\n",
       "      <td>84</td>\n",
       "      <td>0.475690</td>\n",
       "      <td>84</td>\n",
       "      <td>0.450342</td>\n",
       "      <td>48</td>\n",
       "      <td>0.401903</td>\n",
       "      <td>71</td>\n",
       "      <td>0.285918</td>\n",
       "      <td>15</td>\n",
       "      <td>0.107417</td>\n",
       "      <td>111</td>\n",
       "      <td>0.040611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>84</td>\n",
       "      <td>0.488528</td>\n",
       "      <td>114</td>\n",
       "      <td>0.475304</td>\n",
       "      <td>108</td>\n",
       "      <td>0.445780</td>\n",
       "      <td>122</td>\n",
       "      <td>0.401125</td>\n",
       "      <td>122</td>\n",
       "      <td>0.284165</td>\n",
       "      <td>5</td>\n",
       "      <td>0.098688</td>\n",
       "      <td>153</td>\n",
       "      <td>0.039448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>91</td>\n",
       "      <td>0.487887</td>\n",
       "      <td>90</td>\n",
       "      <td>0.474857</td>\n",
       "      <td>132</td>\n",
       "      <td>0.444659</td>\n",
       "      <td>132</td>\n",
       "      <td>0.391399</td>\n",
       "      <td>125</td>\n",
       "      <td>0.280093</td>\n",
       "      <td>11</td>\n",
       "      <td>0.087084</td>\n",
       "      <td>81</td>\n",
       "      <td>0.037979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>73</td>\n",
       "      <td>0.486395</td>\n",
       "      <td>108</td>\n",
       "      <td>0.473956</td>\n",
       "      <td>90</td>\n",
       "      <td>0.438370</td>\n",
       "      <td>90</td>\n",
       "      <td>0.385972</td>\n",
       "      <td>11</td>\n",
       "      <td>0.265308</td>\n",
       "      <td>57</td>\n",
       "      <td>0.084229</td>\n",
       "      <td>57</td>\n",
       "      <td>0.033173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index    0.2_f1  index   0.25_f1  index    0.3_f1  index   0.35_f1  \\\n",
       "0       53  0.503686     16  0.502438     39  0.497604     39  0.484405   \n",
       "1       20  0.503683      4  0.502213      3  0.493571     57  0.483656   \n",
       "2       16  0.503532     39  0.501544     21  0.493405      3  0.480046   \n",
       "3       14  0.503526     20  0.501452     22  0.492306     58  0.476445   \n",
       "4       26  0.503494     53  0.501002     45  0.492275    111  0.476319   \n",
       "..     ...       ...    ...       ...    ...       ...    ...       ...   \n",
       "157    120  0.489312     73  0.475981     72  0.451142    158  0.404111   \n",
       "158     78  0.489058     84  0.475690     84  0.450342     48  0.401903   \n",
       "159     84  0.488528    114  0.475304    108  0.445780    122  0.401125   \n",
       "160     91  0.487887     90  0.474857    132  0.444659    132  0.391399   \n",
       "161     73  0.486395    108  0.473956     90  0.438370     90  0.385972   \n",
       "\n",
       "     index    0.4_f1  index   0.45_f1  index    0.5_f1  \n",
       "0        3  0.442011      0  0.307056    102  0.186533  \n",
       "1       39  0.434485     24  0.297437      0  0.185379  \n",
       "2       31  0.433801    102  0.290820     24  0.180145  \n",
       "3       57  0.433126     84  0.290424     18  0.176986  \n",
       "4      111  0.432711    103  0.290160    156  0.173702  \n",
       "..     ...       ...    ...       ...    ...       ...  \n",
       "157    107  0.290950     17  0.108869      5  0.041271  \n",
       "158     71  0.285918     15  0.107417    111  0.040611  \n",
       "159    122  0.284165      5  0.098688    153  0.039448  \n",
       "160    125  0.280093     11  0.087084     81  0.037979  \n",
       "161     11  0.265308     57  0.084229     57  0.033173  \n",
       "\n",
       "[162 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loops_run = results.at[1, 'total_loops']\n",
    "\n",
    "score_2_f1 = pd.DataFrame(results['0.2_f1'].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "score_25_f1 = pd.DataFrame(results['0.25_f1'].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "score_3_f1 = pd.DataFrame(results['0.3_f1'].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "score_35_f1 = pd.DataFrame(results['0.35_f1'].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "score_4_f1 = pd.DataFrame(results['0.4_f1'].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "score_45_f1 = pd.DataFrame(results['0.45_f1'].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "score_5_f1 = pd.DataFrame(results['0.5_f1'].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "\n",
    "all_f1_scores = pd.concat([score_2_f1, score_25_f1, score_3_f1, score_35_f1, score_4_f1, score_45_f1, score_5_f1], axis = 1)\n",
    "all_f1_scores = all_f1_scores\n",
    "all_f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3851a4",
   "metadata": {},
   "source": [
    "## All models are not better than Logistic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6c1430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
